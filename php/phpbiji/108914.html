<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0, minimal-ui">
    <title>Python之基于Keras的扩展性用法示例_PHP教程_IDC笔记</title>
    <meta name="keywords" content="PHP,PHP笔记,PHP教程" />
    <meta name="description" content="这篇文章主要为大家详细介绍了Python之基于Keras的扩展性用法示例，具有一定的参考价值，可以用来参考一下。<br />
<br />
感兴趣的小伙伴，下面一起跟随php教程的雯雯来看看吧！<br />
Keras是一个用" />
    <meta content="Responsive admin theme build on top of Bootstrap 4" name="description" />
    <meta content="idcnote.com" name="author" />
    <link rel="shortcut icon" href="/skin1/images/favicon.ico">
    <!--Morris Chart CSS -->
    <link rel="stylesheet" href="/skin1/css/morris.css">
    <link href="/skin1/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="/skin1/css/metismenu.min.css" rel="stylesheet" type="text/css">
    <link href="/skin1/css/icons.css" rel="stylesheet" type="text/css">
    <link href="/skin1/css/style.css" rel="stylesheet" type="text/css">
<link href="/SyntaxHighlighter/shCoreDefault.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="/SyntaxHighlighter/shCore.js"></script>
<script type="text/javascript">
 SyntaxHighlighter.all();
</script>
<script>
var paras = document.getElementsByTagName("pre");
for ( var i=0;i<paras.length;i++ ) {
    paras[i].setAttribute("class","brush:php;toolbar:false");     
}
</script>
</head>
<body>
<!-- Begin page -->
		<div id="wrapper">
			<!-- Top Bar Start -->
			<div class="topbar">
				<!-- LOGO -->
				<div class="topbar-left">
					<a href="/" class="logo">
						<span class="logo-light">
                            <i class="mdi mdi-camera-control"></i>IDC笔记
                        </span>
						<span class="logo-sm">
                            <i class="mdi mdi-camera-control"></i>
                        </span>
					</a>
				</div>
				<nav class="navbar-custom">
					<ul class="navbar-right list-inline float-right mb-0">
						<!--<li class="dropdown notification-list list-inline-item d-none d-md-inline-block">
							<a class="nav-link waves-effect" href="#" id="btn-fullscreen">
								<i class="mdi mdi-arrow-expand-all noti-icon"></i>
							</a>
						</li>
						<li class="dropdown notification-list list-inline-item">
							<div class="dropdown notification-list nav-pro-img">
								<a class="dropdown-toggle nav-link arrow-none nav-user" data-toggle="dropdown" href="#" role="button" aria-haspopup="false" aria-expanded="false">
									<img src="/skin1/picture/user-4.jpg" alt="user" class="rounded-circle">
								</a>
								<div class="dropdown-menu dropdown-menu-right profile-dropdown ">
									<a class="dropdown-item" href="#">
										<i class="mdi mdi-account-circle"></i> Profile</a>
									<a class="dropdown-item" href="#">
										<i class="mdi mdi-wallet"></i> Wallet</a>
									<a class="dropdown-item d-block" href="#">
										<span class="badge badge-success float-right">11</span>
										<i class="mdi mdi-settings"></i> Settings</a>
									<a class="dropdown-item" href="#">
										<i class="mdi mdi-lock-open-outline"></i> Lock screen</a>
									<div class="dropdown-divider"></div>
									<a class="dropdown-item text-danger" href="#">
										<i class="mdi mdi-power text-danger"></i> Logout</a>
								</div>
							</div>
						</li>
						-->
					</ul>
					<ul class="list-inline menu-left mb-0">
						<li class="float-left">
							<button class="button-menu-mobile open-left waves-effect">
                            <i class="mdi mdi-menu"></i>
                        </button>
						</li>
						<li class="d-none d-md-inline-block">
							<form role="search" class="app-search">
								<div class="form-group mb-0">
									<input type="text" class="form-control" placeholder="Search..">
									<button type="submit"><i class="fa fa-search"></i></button>
								</div>
							</form>
						</li>
					</ul>
				</nav>
			</div>
<!-- ========== Left Sidebar Start ========== -->
<div class="left side-menu">
    <div class="slimscroll-menu" id="remove-scroll">
    <!--- Sidemenu -->
    <div id="sidebar-menu">
    <!-- Left Menu Start -->
    <ul class="metismenu" id="side-menu">
			<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP简介			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/jianjie/1.html">PHP简介</a></li><li><a href="/php/jianjie/2.html">PHP用途</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP基本语法			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/yufa/3.html">分离HTML</a></li><li><a href="/php/yufa/4.html">指令分隔符</a></li><li><a href="/php/yufa/5.html">PHP注释</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP类型			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/phpleixing/6.html">PHP类型简介</a></li><li><a href="/php/phpleixing/7.html">PHP类型之布尔类型</a></li><li><a href="/php/phpleixing/8.html">PHP类型之整型</a></li><li><a href="/php/phpleixing/9.html">PHP类型之浮点型</a></li><li><a href="/php/phpleixing/10.html">PHP类型之字符串</a></li><li><a href="/php/phpleixing/11.html">PHP类型之数组</a></li><li><a href="/php/phpleixing/12.html">PHP类型之对象</a></li><li><a href="/php/phpleixing/13.html">PHP类型之资源类型</a></li><li><a href="/php/phpleixing/14.html">PHP类型之NULL</a></li><li><a href="/php/phpleixing/15.html">PHP类型之伪类型</a></li><li><a href="/php/phpleixing/16.html">PHP类型之类型判别</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP变量			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/phpbianliang/17.html">PHP变量之基础</a></li><li><a href="/php/phpbianliang/18.html">PHP变量之预定义变量</a></li><li><a href="/php/phpbianliang/19.html">PHP变量之变量范围</a></li><li><a href="/php/phpbianliang/20.html">PHP变量之可变变量</a></li><li><a href="/php/phpbianliang/21.html">PHP变量之外部变量</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP运算符			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/yunsuanfu/22.html">PHP运算符优先级</a></li><li><a href="/php/yunsuanfu/23.html">算术运算符</a></li><li><a href="/php/yunsuanfu/24.html">赋值运算符</a></li><li><a href="/php/yunsuanfu/25.html">位运算符</a></li><li><a href="/php/yunsuanfu/26.html">比较运算符</a></li><li><a href="/php/yunsuanfu/27.html">错误控制运算符</a></li><li><a href="/php/yunsuanfu/28.html">执行运算符</a></li><li><a href="/php/yunsuanfu/29.html">递增/递减运算符</a></li><li><a href="/php/yunsuanfu/30.html">逻辑运算符</a></li><li><a href="/php/yunsuanfu/31.html">字符串运算符</a></li><li><a href="/php/yunsuanfu/32.html">数组运算符</a></li><li><a href="/php/yunsuanfu/33.html">类型运算符</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP控制结构			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/jiegou/34.html">PHP控制结构之if</a></li><li><a href="/php/jiegou/35.html">PHP控制结构之else</a></li><li><a href="/php/jiegou/36.html">PHP控制结构之elseif/else if</a></li><li><a href="/php/jiegou/37.html">PHP控制结构之替代语法</a></li><li><a href="/php/jiegou/38.html">PHP控制结构之while</a></li><li><a href="/php/jiegou/39.html">PHP控制结构之do-while</a></li><li><a href="/php/jiegou/40.html">PHP控制结构之for</a></li><li><a href="/php/jiegou/41.html">PHP控制结构之foreach</a></li><li><a href="/php/jiegou/42.html">PHP控制结构之break</a></li><li><a href="/php/jiegou/43.html">PHP控制结构之continue</a></li><li><a href="/php/jiegou/44.html">PHP控制结构之switch</a></li><li><a href="/php/jiegou/45.html">PHP控制结构之declare</a></li><li><a href="/php/jiegou/46.html">PHP控制结构之return</a></li><li><a href="/php/jiegou/47.html">PHP控制结构之require</a></li><li><a href="/php/jiegou/48.html">PHP控制结构之include</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP函数			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/hanshu/52.html">用户自定义函数</a></li><li><a href="/php/hanshu/53.html">函数的参数</a></li><li><a href="/php/hanshu/54.html">返回值</a></li><li><a href="/php/hanshu/55.html">可变函数</a></li><li><a href="/php/hanshu/56.html">内部（内置）函数</a></li><li><a href="/php/hanshu/57.html">匿名函数</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP类与对象			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/phpduixiang/58.html">类与对象前言</a></li><li><a href="/php/phpduixiang/59.html">基本概念</a></li><li><a href="/php/phpduixiang/60.html">属性</a></li><li><a href="/php/phpduixiang/61.html">类常量</a></li><li><a href="/php/phpduixiang/62.html">自动加载对象</a></li><li><a href="/php/phpduixiang/63.html">构造函数和析构函数</a></li><li><a href="/php/phpduixiang/64.html">访问控制</a></li><li><a href="/php/phpduixiang/65.html">对象继承</a></li><li><a href="/php/phpduixiang/66.html">Static关键字</a></li><li><a href="/php/phpduixiang/67.html">抽象类</a></li><li><a href="/php/phpduixiang/68.html">接口</a></li><li><a href="/php/phpduixiang/69.html">Traits</a></li><li><a href="/php/phpduixiang/70.html">重载</a></li><li><a href="/php/phpduixiang/71.html">对象迭代</a></li><li><a href="/php/phpduixiang/72.html">设计模式</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP异常处理			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/yichang/81.html">异常处理</a></li><li><a href="/php/yichang/82.html">扩展PHP内置的异常处理类</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> PHP函数库按分类			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/phpku/83.html">数组</a></li><li><a href="/php/phpku/84.html">Classes/Objects</a></li><li><a href="/php/phpku/85.html">Date/Time</a></li><li><a href="/php/phpku/86.html">Directories</a></li><li><a href="/php/phpku/87.html">错误处理</a></li><li><a href="/php/phpku/88.html">Program execution</a></li><li><a href="/php/phpku/89.html">Filesystem</a></li><li><a href="/php/phpku/90.html">Filter</a></li><li><a href="/php/phpku/91.html">Function Handling</a></li><li><a href="/php/phpku/92.html">PHP 选项/信息</a></li><li><a href="/php/phpku/93.html">Mail</a></li><li><a href="/php/phpku/94.html">Math</a></li><li><a href="/php/phpku/95.html">Misc.</a></li><li><a href="/php/phpku/96.html">Network</a></li><li><a href="/php/phpku/97.html">输出控制</a></li>		</ul>
	</li>
		<li>
		<a href="javascript:void(0);" class="waves-effect">
			<i class="icon-share"></i>
			<span> php基础			<span class="float-right menu-arrow">
			<i class="mdi mdi-chevron-right"></i>
			</span> 
			</span>
		</a>
		<ul class="submenu">
			 <li><a href="/php/phpbiji/108377.html"></a></li><li><a href="/php/phpbiji/108376.html"></a></li><li><a href="/php/phpbiji/108380.html"></a></li><li><a href="/php/phpbiji/108379.html"></a></li><li><a href="/php/phpbiji/108378.html"></a></li><li><a href="/php/phpbiji/108381.html"></a></li><li><a href="/php/phpbiji/108382.html"></a></li><li><a href="/php/phpbiji/108384.html"></a></li><li><a href="/php/phpbiji/108383.html"></a></li><li><a href="/php/phpbiji/108385.html"></a></li><li><a href="/php/phpbiji/108386.html"></a></li><li><a href="/php/phpbiji/108388.html"></a></li><li><a href="/php/phpbiji/108387.html"></a></li><li><a href="/php/phpbiji/108389.html"></a></li><li><a href="/php/phpbiji/108391.html"></a></li>		</ul>
	</li>
		<li>
	    <a href="/php/biji/" class="waves-effect">
		    <i class="icon-share"></i>
		    <span>PHP笔记
		       	<span class="float-right menu-arrow">
		       	<i class="mdi mdi-chevron-right"></i>
		       	</span>
		    </span>
	    </a>
	</li>
	</ul>
</div>
<!-- Sidebar -->
<div class="clearfix"></div>
</div>
<!-- Sidebar -left -->
</div>
<!-- Left Sidebar End -->
<!-- Start right Content here -->
<div class="content-page">
	<div class="content">
		<div class="container-fluid">
			<div class="page-title-box">
				<div class="row align-items-center">
					<div class="col-sm-6">
						<h1 class="page-title">Python之基于Keras的扩展性用法示例</h1>
					</div>
				</div>
				<!-- end row -->
			</div>
			<!-- end page-title -->
			<!-- START ROW -->
			<div class="panel panel-forbid">
				<div class="panel-title"><i class="fa fa fa-file-text fa-fw"></i>内容摘要</div>
			    <div class="panel-content">
			    <span>这篇文章主要为大家详细介绍了Python之基于Keras的扩展性用法示例，具有一定的参考价值，可以用来参考一下。<br />
<br />
感兴趣的小伙伴，下面一起跟随php教程的雯雯来看看吧！<br />
Keras是一个用</span>                                     
		    	</div>
			    <div class="panel-title"><i class="fa fa fa-file-text fa-fw"></i>文章正文</div>
			    <div class="panel-content">
			    <span><p>这篇文章主要为大家详细介绍了Python之基于Keras的扩展性用法示例，具有一定的参考价值，可以用来参考一下。</p>

<p>感兴趣的小伙伴，下面一起跟随php教程的雯雯来看看吧！</p>
<p>Keras是一个用于在python上搭神经网络模型的框架，语法和torch比较相似。我个人认为Keras最大的特点是包装很好，一些在训练过程中要输出的方法和常用的优化函数、目标函数都已经内置了，非常适合用来写大作业。Keras和python的哲学有些相似，那就是尽量不自己造轮子。</p>
<p>但是最近逛知乎，看到有答案说，Keras只能用来搭一些世面上已经普及的网络，和其它框架相比比较小白。换句话说，就是Keras的扩展性不好。作为一个试用过theano、tensorflow、torch、caffe等框架，最后定居在Keras的人，我对此不太同意。事实上，Keras拥有不错的扩展性，这一方面是因为设计时就留好的接口，另一方面是因为清晰的代码结构，让你可以有很多自定义的空间。所以下面用几个例子介绍在Keras中如何自定义层和各种方法。</p>
<h2>0、backend</h2>
<p>如果想在Keras中自定义各种层和函数，一定会用到的就是backend。一般导入的方法是</p>
<p>代码如下：</p>
<pre>
<code>
from keras import backend as K</code></pre>
<p>基于Keras的扩展性使用</p>
<p>这是因为Keras可以有两种后台，即theano和tensorflow，所以一些操作张量的函数可能是随后台的不同而不同的，</p>
<p>通过引入这个backend，就可以让Keras来处理兼容性。</p>
<p>比如求x的平均，就是K.mean(x)。backend文件本身在keras/backend文件夹下，可以通过阅读代码来了解backend都支持哪些操作。backend里面函数很多，一般都够用了。</p>
<h2>1、Lambda 层</h2>
<p>如果你只是想对流经该层的数据做个变换，而这个变换本身没有什么需要学习的参数，那么直接用Lambda Layer是最合适的了。</p>
<p>导入的方法是</p>
<p>代码如下：</p>
<pre>
<code>
from keras.layers.core import Lambda</code></pre>
<p>基于Keras的扩展性使用</p>
<p>Lambda函数接受两个参数，第一个是输入张量对输出张量的映射函数，第二个是输入的shape对输出的shape的映射函数。比如想构建这样一个层，流经该层的数据会被减去平均值，那么可以这样定义：</p>
<p>代码如下：</p>
<pre>
<code>
def sub_mean(x):
    x -= K.mean(x,axis=1,keepdims=True)
    return x
model.add( Lambda(sub_mean,output_shape=lambda input_shape:input_shape ))</code></pre>
<p>基于Keras的扩展性使用</p>
<p>因为输出的shape和输入的shape是一样的，第二个参数就直接用了恒等映射。</p>
<p>把模型完整地建立出来：</p>
<p>代码如下：</p>
<pre>
<code>
def get_submean_model():
    model = Sequential()
    model.add(Dense(5,input_dim=7))
    def sub_mean(x):
        x -= K.mean(x,axis=1,keepdims=True)
        return x
    model.add( Lambda(sub_mean,output_shape=lambda input_shape:input_shape))
    model.compile(optimizer='rmsprop',loss='mse')
    return model
model = get_submean_model()
res=model.predict(np.random.random((3,7)))</code></pre>
<p>基于Keras的扩展性使用</p>
<p>得到地res的平均值是[ 5.96046448e-08 -5.96046448e-08 0.00000000e+00]，可见确实实现了减去均值的作用。</p>
<h2>2、自定义非递归层</h2>
<p>如果自己想定义的层中有需要学习的变量，那么就不能用lambda层了，需要自己写一个出来。</p>
<p>比如说我想定义一个层，它的效果是对张量乘一个正对角阵（换句话说，输入向量与一个要学习的向量逐元素相乘），那么可以这样写：</p>
<p>首先要导入基类</p>
<p>代码如下：</p>
<pre>
<code>
from keras.engine.topology import Layer</code></pre>
<p>基于Keras的扩展性使用</p>
<p>然后对MyLaber定义如下：</p>
<p>代码如下：</p>
<pre>
<code>
class MyLayer(Layer):
    def __init__(self,output_dim,**kw):
        self.output_dim = output_dim
        super(MyLayer,self).__init__(**kw)
    def build(self,input_shape):
        input_dim = input_shape[1]
        assert(input_dim == self.output_dim)
        inital_SCALER = np.ones((input_dim,))*1000
        self.SCALER = K.variable(inital_SCALER)
        self.trainable_weights = [self.SCALER]
        super(MyLayer,self).build(input_shape)
    def call(self,x,mask=None):
        #return x - K.mean(x,axis=1,keepdims=True)
        x *= self.SCALER
        return x
    def get_output_shape_for(self,input_shape):
        return input_shape</code></pre>
<p>基于Keras的扩展性使用</p>
<p>主要参照Keras内置的层的写法，比如Dense在keras/layers/core.py中，要把能学习的参数放在self.trainable_weights中。这里把初始值设成了1000是为了让该层的效果更显著。然后把模型写全来测试一下</p>
<p>代码如下：</p>
<pre>
<code>
def get_mylayer_model():
    model = Sequential()
    model.add(Dense(5,input_dim=7))
    model.add(MyLayer(5))
    model.compile(optimizer='rmsprop',loss='mse')
    return model
model = get_mylayer_model()
res=model.predict(np.random.random((3,7)))
print res</code></pre>
<p>基于Keras的扩展性使用</p>
<p>res如下：</p>
<blockquote>
<p>[[ 271.2746582 -1053.31506348 147.17185974 -1120.33740234 609.54876709]</p>
<p>[ -263.69671631 -390.41921997 291.17721558 -594.58721924 615.97369385]</p>
<p>[ -46.58752823 -733.11328125 -21.9815979 -570.79351807 649.44158936]]</p></blockquote>
<p>都是很大的数，而不加MyLayer时每个值一般也不超过+-2，这个层确实起了作用。</p>
<p>在fit之前调用model.get_weights()，看到该层的权重都是1000，随便随机出来个测试集，fit几千个epoch只后，loss变得很小，MyLayer的权重变成了997左右，而前面一层Dense的权重都成10^-4量级，说明MyLayer中的参数也确实是可学习的。</p>
<h2>3、自定义损失函数</h2>
<p>Keras内置的损失函数都在keras/objectives.py中，比如mse的定义是：</p>
<p>代码如下：</p>
<pre>
<code>
def mean_squared_error(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)</code></pre>
<p>基于Keras的扩展性使用</p>
<p>按照相同的格式，可以定义自己的损失函数。比如我们想要差值的4次方的平均作为损失函数：</p>
<p>代码如下：</p>
<pre>
<code>
def my_object(y_true,y_pred):
    return K.mean(K.square(K.square(y_pred-y_true)),axis=-1)</code></pre>
<p>基于Keras的扩展性使用</p>
<p>把模型写全：</p>
<p>代码如下：</p>
<pre>
<code>
def get_myobj_model():
    model = Sequential()
    model.add(Dense(5,input_dim=7))
    model.add(Dense(3))
    def my_object(y_true,y_pred):
        return K.mean(K.square(K.square(y_pred-y_true)),axis=-1)
    model.compile(optimizer='sgd',loss=my_object)
    return model
model = get_myobj_model()</code></pre>
<p>基于Keras的扩展性使用</p>
<p>能自定义损失函数是非常重要一环，它极大的扩展了网络的应用。例如希望用cnn训练出来一个前后景分割的滤波器，它的输出的像素在对应前景的位置是1，在对应后景的位置是0。不但希望网络输出的值的mse小，而且希望0和1分别都连在一起，不要出来雪花状的输出。那么自定义损失函数就能做到了，实际是把两个损失函数放到了一个损失函数中。</p>
<p>另外一些很有用的损失函数如warp-ctc，就可以在这里集成进模型。</p>
<h2>4、自定义递归层</h2>
<p>递归层的定义方法和非递归层不太一样。根据Keras内LSTM的写法，它还有一个reset_states函数和step函数，这是由递归的性质决定的。例子都在keras/layers/recurrent.py中。</p>
<p>之前看学长用lasagne写的LSTM的变体，看得我想哭，还不如在Keras中把LSTM得代码复制过来修修改改。不过LSTM也不能直接复制过来，还需要import几个依赖：</p>
<p>代码如下：</p>
<pre>
<code>
rom keras.layers.recurrent import LSTM,Recurrent,time_distributed_dense
from keras import initializations,regularizers,activations
from keras.engine import InputSpec</code></pre>
<p>基于Keras的扩展性使用</p>
<h2>5、自定义优化函数</h2>
<p>Keras的代码确实好，耦合度很低。Keras内置的优化函数在keras/optimizers.py中，基类Optimizer也在这个文件里。例如把它内置的SGD算法拷贝到自己的文件中，只要先from keras.optimizers import Optimizer就能编译通过。</p>
<p>有时候要得到state-of-the-art的结果，需要用sgd加动量法充分收敛。比如学习率0.01学习上100epoch，再把学习率减半，再学100epoch，依次类推。如果不自定义优化函数的话，就要分阶段调用fit函数，修改学习率，可能还要重新compile。这就不是很优美了。其它一些奇葩的学习策略，也可以通过自定义优化函数来得到。</p>
<h2>6、后记</h2>
<p>Keras确实非常强大，不但能用来写大作业，做一些研究也够用了。Yeah</p>
<p></p>
<h3>补充：keras的扩展性：自定义keras</h3>
<p></p>
<h2>1. 自定义keras</h2>
<p>keras是一种深度学习的API，能够快速实现你的实验。keras也集成了很多预训练的模型，可以实现很多常规的任务，如图像分类。TensorFlow 2.0之后tensorflow本身也变的很keras化。</p>
<p>另一方面，keras表现出高度的模块化和封装性，所以有的人会觉得keras不易于扩展， 比如实现一种新的Loss，新的网络层结构；其实可以通过keras的基础模块进行快速的扩展，实现更新的算法。</p>
<p>本文就keras的扩展性，总结了对layer，model和loss的自定义。</p>
<h2>2. 自定义keras layers</h2>
<p>layers是keras中重要的组成部分，网络结构中每一个组成都要以layers来表现。keras提供了很多常规的layer，如Convolution layers，pooling layers， activation layers， dense layers等， 我们可以通过继承基础layers来扩展自定义的layers。</p>
<h3>2.1 base layer</h3>
<p>layer实了输入tensor和输出tensor的操作类，以下为base layer的5个方法，自定义layer只要重写这些方法就可以了。</p>
<p>init(): 定义自定义layer的一些属性</p>
<p>build(self, input_shape)：定义layer需要的权重weights</p>
<p>call(self, *args, **kwargs)：layer具体的操作，会在调用自定义layer自动执行</p>
<p>get_config(self)：layer初始化的配置，是一个字典dictionary。</p>
<p>compute_output_shape(self,input_shape)：计算输出tensor的shape</p>
<h3>2.2 例子</h3>
<p>代码如下：</p>
<pre>
<code>
# 标准化层
class InstanceNormalize(Layer):
    def __init__(self, **kwargs):
        super(InstanceNormalize, self).__init__(**kwargs)
        self.epsilon = 1e-3
            
    def call(self, x, mask=None):
        mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)
        return tf.div(tf.subtract(x, mean), tf.sqrt(tf.add(var, self.epsilon)))
                                                 
    def compute_output_shape(self,input_shape):
        return input_shape
# 调用
inputs = keras.Input(shape=(None, None, 3))
x = InstanceNormalize()(inputs)</code></pre>
<p>基于Keras的扩展性使用</p>
<p>代码如下：</p>
<pre>
<code>
# 可以通过add_weight() 创建权重
class SimpleDense(Layer):
  def __init__(self, units=32):
      super(SimpleDense, self).__init__()
      self.units = units
  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)
  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b
# 调用
inputs = keras.Input(shape=(None, None, 3))
x = SimpleDense(units=64)(inputs)</code></pre>
<p>基于Keras的扩展性使用</p>
<h2>3. 自定义keras model</h2>
<p>我们在定义完网络结构时，会把整个工作流放在 keras.Model， 进行 compile(), 然后通过 fit() 进行训练过程。执行 fit() 的时候，执行每个 batch size data 的时候，都会调用 Model 中train_step(self, data)</p>
<p>代码如下：</p>
<pre>
<code>
from keras.models import Sequential
from keras.layers import Dense, Activation
model = Sequential()
model.add(Dense(units=64, input_dim=100))
model.add(Activation("relu"))
model.add(Dense(units=10))
model.add(Activation("softmax"))
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5, batch_size=32)
</code></pre>
<p>基于Keras的扩展性使用</p>
<p>当你需要自己控制训练过程的时候，可以重写Model的train_step(self, data)方法</p>
<p>代码如下：</p>
<pre>
<code>
class CustomModel(keras.Model):
    def train_step(self, data):
        # Unpack the data. Its structure depends on your model and
        # on what you pass to `fit()`.
        x, y = data
        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)  # Forward pass
            # Compute the loss value
            # (the loss function is configured in `compile()`)
            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)
        # Compute gradients
        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        # Update weights
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))
        # Update metrics (includes the metric that tracks the loss)
        self.compiled_metrics.update_state(y, y_pred)
        # Return a dict mapping metric names to current value
        return {m.name: m.result() for m in self.metrics}
import numpy as np
# Construct and compile an instance of CustomModel
inputs = keras.Input(shape=(32,))
outputs = keras.layers.Dense(1)(inputs)
model = CustomModel(inputs, outputs)
model.compile(optimizer="adam", loss="mse", metrics=["mae"])
# Just use `fit` as usual
x = np.random.random((1000, 32))
y = np.random.random((1000, 1))
model.fit(x, y, epochs=3)</code></pre>
<p>基于Keras的扩展性使用</p>
<h2>4. 自定义keras loss</h2>
<p>keras实现了交叉熵等常见的loss，自定义loss对于使用keras来说是比较常见，实现各种魔改loss，如focal loss。</p>
<p>我们来看看keras源码中对loss实现</p>
<p>代码如下：</p>
<pre>
<code>
def categorical_crossentropy(y_true, y_pred):
    return K.categorical_crossentropy(y_true, y_pred)
def mean_squared_error(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)
</code></pre>
<p>基于Keras的扩展性使用</p>
<p>可以看出输入是groud true y_true和预测值y_pred， 返回为计算loss的函数。自定义loss可以参照如此模式即可。</p>
<p>代码如下：</p>
<pre>
<code>
def focal_loss(weights=None, alpha=0.25, gamma=2):
    r"""Compute focal loss for predictions.
        Multi-labels Focal loss formula:
            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)
                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.
    # https://github.com/ailias/Focal-Loss-implement-on-Tensorflow/blob/master/focal_loss.py
    Args:
     prediction_tensor: A float tensor of shape [batch_size, num_anchors,
        num_classes] representing the predicted logits for each class
     target_tensor: A float tensor of shape [batch_size, num_anchors,
        num_classes] representing one-hot encoded classification targets
     weights: A float tensor of shape [batch_size, num_anchors]
     alpha: A scalar tensor for focal loss alpha hyper-parameter
     gamma: A scalar tensor for focal loss gamma hyper-parameter
    Returns:
        loss: A (scalar) tensor representing the value of the loss function
    """
    def _custom_loss(y_true, y_pred):
        sigmoid_p = tf.nn.sigmoid(y_pred)
        zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)
        # For poitive prediction, only need consider front part loss, back part is 0;
        # target_tensor &gt; zeros &lt;=&gt; z=1, so poitive coefficient = z - p.
        pos_p_sub = array_ops.where(y_true &gt; zeros, y_true - sigmoid_p, zeros)
        # For negative prediction, only need consider back part loss, front part is 0;
        # target_tensor &gt; zeros &lt;=&gt; z=1, so negative coefficient = 0.
        neg_p_sub = array_ops.where(y_true &gt; zeros, zeros, sigmoid_p)
        per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \
                              - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(
            tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))
        return tf.reduce_sum(per_entry_cross_ent)
    return _custom_loss</code></pre>
<p>基于Keras的扩展性使用</p>
<h2>5. 总结</h2>
<p>本文分享了keras的扩展功能，扩展功能其实也是实现Keras模块化的一种继承实现。</p>
<h3>总结如下：</h3>
<p>继承Layer实现自定义layer， 记住bulid() call()</p>
<p>继续Model实现train_step定义训练过程，记住梯度计算tape.gradient(loss, trainable_vars) ，权重更新optimizer.apply_gradients, 计算evaluate compiled_metrics.update_state(y, y_pred)</p>
<p>魔改loss，记住groud true y_true和预测值y_pred输入，返回loss function</p>
<p>以上为个人经验，希望能给大家一个参考，也希望大家多多支持php教程。</p>

<p>注：关于Python之基于Keras的扩展性用法示例的内容就先介绍到这里，更多相关文章的可以留意</span>                                     
		    	</div>
		    	<div class="panel-title"><i class="fa fa fa-file-text fa-fw"></i>代码注释</div>
			    <div class="panel-content">
			    <span></span>                                     
		    	</div>

			</div>

			<!-- END ROW -->
			<div class="newsPage">
				<div class="newsPageTurn">
				    <span><a>上一篇</a><a href='/php/phpbiji/108905.html'>解决PHP利用file_exists函数不支持中文名的问题</a><a>下一篇</a><a href='/php/phpbiji/108915.html'>解决PHP使用Session遇到的一个Permission denied Notice的问题</a></span>
				</div>
			</div>
		</div>


<div id="author-box">
    <h3>作者：喵哥笔记</h3>
        <div class="author-info">
            <div class="author-avatar">
                <img src="/skin1/picture/01.jpg" alt="IDC笔记" class="avatar" width="64" height="64">
            </div>
        <div class="author-description">
            <p>学的不仅是技术，更是梦想！</p>
            <ul class="author-social follows nb">
            	<li>
                    <a target="_blank" href="/" title="IDC笔记">IDC笔记</a>
                </li>
            </ul>
        </div>
        <div class="clear"></div>
    </div>
</div>
<script>
var paras = document.getElementsByTagName("pre");
for ( var i=0;i<paras.length;i++ ) {
    paras[i].setAttribute("class","brush:php;toolbar:false");     
}
</script>
<!-- container-fluid -->
	</div>
<!-- content -->
	<footer class="footer">
	© 2020 IDC笔记 <i class="mdi mdi-heart text-danger"></i>. | 备案号：<a href="https://beian.miit.gov.cn/">辽ICP备18000516号</a>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?674585fbbd2294d3faf910f668ea91b4";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

	</footer>
</div>

</div>
<!-- END wrapper -->
<!-- jQuery  -->
<script src="/skin1/js/jquery.min.js"></script>
<script src="/skin1/js/bootstrap.bundle.min.js"></script>
<script src="/skin1/js/metismenu.min.js"></script>
<script src="/skin1/js/jquery.slimscroll.js"></script>
<script src="/skin1/js/waves.min.js"></script>
<!--Morris Chart-->
<script src="/skin1/js/morris.min.js"></script>
<script src="/skin1/js/raphael.min.js"></script>
<script src="/skin1/js/dashboard.init.js"></script>
<script src="/skin1/js/app.js"></script>
<script src="/foot.js"></script>
</body>
</html>